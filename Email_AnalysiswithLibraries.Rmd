---
title: "Email_Analysis"
author: "Jonathan Roberts"
date: "7 April 2017"
output: 
    html_notebook: default
    html_document: default
    
---

#Get up and running
##Global RMarkdown Parameters
Are set here

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```


##Install the R markdown packages and library

```{r message = FALSE, warning = TRUE}
libraries <- c("rmarkdown", "tidytext", "magrittr", "dplyr", "tidyr", "lazyeval", "purrr")

#UNCOMMENT TO INSTALL PACKAGES
lapply(libraries, install.packages)
lapply(libraries, library, character.only = TRUE)
```

## Working Directory: 
Set up where you are working and what is in the directory and what objects you have
 
```{r}

# SET THE WORKING DIRECTORY
setwd("/Users/jonathanroberts/Documents/R/Email_Analysis")
dir()
ls()

```

#Assignment: Part 1 & 2


#Playing Around with Email Data
Shot term aim will be to have a function where you send it a person/email adress and you can 
Long term aim might be to do:
topic modelling and see how the changes over time
LSA/clustering and see how that changes over time
Maybe doing that sort of thing when passing a set of users over to it

Another area to explore might be linking to other people's data and having some network diagrams perhaps.

Ultimately i'd like to get something which might be a jonbot and suggest responses to emails for me...


##Write in the data and have a look at it

```{r}

raw_data <- read.csv("../SensitiveData/2017_sent_emails.CSV", colClasses = "character")
email_stopwords <- read.csv("../SensitiveData/email_stopwords.CSV", colClasses = "character")

#Have a look at the data
class(raw_data)
class(email_stopwords)

#rename the columns of the text and recipients so that goes into functions further down
colnames(raw_data)
colnames(raw_data)[2]<-"email"
colnames(raw_data)[6]<-"who"
colnames(raw_data)

raw_data[,6]
class(raw_data[,6])

charmatch("Wyatt, Ross",raw_data[,6])

```


##Pull out relevant subsets of the data
Write a function that receives the rawdata and an email address and send back the raw data for that person, and possible just the email text and not all the rest of the data.

First time round probably do some loose search on whether they were one of the people emailed, maybe a function like contains - although this isn't an r thing.

This function needs your data to have a 'who' column that it 'filters'.

```{r}


##TODO: this should be able to pass more than one person, ie. a vector or names and return.
## It needs to be 'OR' for all of the names that you pass. But either here of later you need to split them out so that you have the length of the vector and can loop around it.
## I think you do that bit elsewhere, where you call the whole function, then just call this bit one name at a time...

##TODO: this needs to be more robust to loewer case etc

individual_emails<-function(source_data, who = "Ross"){
        
        #vector to take the instances where the match is true
        v<-grepl(who, source_data$who)
        #filter on matches
        person_data<-(source_data[v,])
        return(person_data)
}

##uncomment the following line when ready to call the function
#text_to_analyse <- individual_emails(raw_data,2,5)

#TODO: note that charmatch doesn't work

sam<-individual_emails(raw_data, who="Mike")


```


## Calculate common words and bigrams
This function gives the most common single words or bigrams not including stopwords.
It takes a dataframe as an argument, which must have a column called "Subject" that is
the answers to the question of interest, and one called "who"" that looks at who you are sending to.


```{r}


###HELPER FUNCTIONS###

## TODO: i want to be able to call to $email or $Subject in the defintion of the function, but can't do this in the obvious way.

mostcommon <- function(text_df,n=1,x=20){
  if(n==1){
    #manipulate the data so that each word has its own row
    tidy_Qdf<- text_df %>% unnest_tokens(word,Subject,to_lower=TRUE)
    #remove stopwords
    clean_Qdf <- tidy_Qdf %>% anti_join(stop_words)  
    clean_Qdf <- clean_Qdf %>% anti_join(email_stopwords)
    #count the occurrences of each word, sort by the number of occurrences, and take the top x
    top_x <- (clean_Qdf %>% count(word,sort=TRUE))[1:x,]
  }
  else if(n==2){
    #manipulate the data so that each bigram has its own row
    tidy_Qdf<- text_df %>% unnest_tokens(bigram,Subject,to_lower=TRUE,token="ngrams",n=2)
    #separate bigrams into individual words
    bigrams_separated <- tidy_Qdf %>% separate(bigram, c("word1", "word2"), sep = " ")
    #remove cases where one of the words is a stopword
    bigrams_filtered <- bigrams_separated %>%
      filter(!word1 %in% stop_words$word) %>%
      filter(!word2 %in% stop_words$word)
    
    #count the occurrences of word pairs, sort by the number of occurrences, and take the top x
    top_x <- as.data.frame((bigrams_filtered %>% count(word1, word2, sort = TRUE))[1:x,])
    
    #rejoin the words back into bigrams
    top_x$phrase <- sapply(1:x,
                           function(x)
                             paste(top_x[x,]$word1,top_x[x,]$word2))
    #only keep the bigrams
    top_x <- top_x[,!(names(top_x) %in% c("word1","word2"))]
  }
  who<-rep(text_df$who[1],x)
  return(cbind(top_x,who))
}


```


##Set the loop to go around who is emailing you

TODO: The rbind process is inefficient accroding to Robin, so probably want to do this is a slightly different way to speed up in due course.

NOTE: The code requires you to input whose name you are looking for, this could be in an interface in future.


```{r}

####Actual work####

#Set up a vector of people you want to look for in your email.
sent_to<-c("Ross")

# loop around all the people calling a function to filter relevant emails then 
# send to commonWords & commonBigrams functions
for (i in 1:length(sent_to)){
        
        if (i==1){ 
                input_data<-individual_emails(raw_data, who=sent_to[i])
                commonWords <- input_data %>% mostcommon( x=20)
                commonBigrams <- input_data %>% mostcommon(n=2, x=20) %>% cbind(sent_to[i])
        }
        else {
                input_data<-individual_emails(raw_data, who=sent_to[i])
                commonWords <- input_data %>% mostcommon( x=20) %>% rbind(commonWords)
                commonBigrams <- input_data %>% mostcommon(n=2, x=20) %>% cbind(sent_to[i]) %>% rbind(commonBigrams)
        }
}


#and write out
write.csv(commonWords,"../SensitiveData/commonWords.csv")
write.csv(commonBigrams,"../SensitiveData/commonBigrams.csv")


```

##Can we plot a few things please

Well barplot is a bit sh1t. 

```{r}

#plot(commonBigrams$`sent_to[i]`, commonBigrams$n)
barplot(commonBigrams$n, names.arg = commonBigrams$phrase, horiz = TRUE)



```



